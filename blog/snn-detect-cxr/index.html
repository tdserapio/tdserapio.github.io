<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detecting Change Between CXR Images Using Siamese Neural Networks -- That's Just About It</title>

    <link rel="stylesheet" href="../styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel="stylesheet">
    <link rel="icon" href="" type="image/x-icon">
</head>
<body>
    <div class="left-container">
        <br>
        <header>Detecting Change Between CXR Images Using Siamese Neural Networks</header>
        <br>
        <h2>Troy Serapio • <i>August 7, 2023</i></h2>
        <hr style="width: 100%;">
        <br>
        <h3>Siamese neural networks, also called twin neural networks, are designed for the comparison of two objects. This architecture is commonly used in image comparison tasks such as verification, duplicate detection, and anomaly detection; in fact, one of the first known uses of this architecture is signature verification. 
            <br><br>From here, we attempted to use Siamese neural networks to detect changes between a series of patient’s chest X-rays (CXRs). More specifically, we will focus on the progression of pleural effusion on the chest X-rays. We will use ImaGenome dataset, which is derived from the MIMIC-CXR dataset. The ImaGenome dataset is a collection of temporal series of CXR images with descriptions.</h3>
        <br>
        <h1>What are Siamese neural networks, exactly?</h1>
        <h3>The Siamese neural network is <a href="https://github.com/tdserapio/CXR-Siamese-Networks/blob/main/sample.py#L73-L76">one neural network</a> that take in two (different) input vectors. In our use case, these input vectors are two CXR images. </h3>
        <div class="images">
            <div class="image" style="flex: 0.3">
                <img src="images/image1.png">
                <div class="emergency_br"></div>
                <subtitle>Taken from ImaGenome dataset</subtitle>
            </div>
            <div class="image" style="flex: 0.3">
                <img src="images/image2.png">
                <div class="emergency_br"></div>
                <subtitle>Taken from ImaGenome dataset</subtitle>
            </div>
        </div>
        <br>
        <h3>These input vectors are then fed into the convolutional neural network, and the neural networks generate <a href="https://github.com/tdserapio/CXR-Siamese-Networks/blob/main/sample.py#L79">two separate embeddings</a> (vectors that are far easier to compare to each other). This could be thought of as the model outputting its own version of the original input.</h3>
        <div class="images">
            <div class="image" style="width: 80%;">
                <img src="images/figure11.png">
                <div class="emergency_br"></div>
                <subtitle>
                    Input to embedding
                </subtitle>
            </div>
        </div>
        <br>
        <h3>These output vectors are concatenated to each other and ran through a <a href="https://github.com/tdserapio/CXR-Siamese-Networks/blob/main/sample.py#L80-L82">multi-layer perceptron</a> to come up with a prediction (eg. whether or not a change was detected). This prediction is then trained on <a href="https://github.com/tdserapio/CXR-Siamese-Networks/blob/main/sample.py#L120-L138">weighted cross-entropy loss</a>, with an Adam optimizer to tweak its weights. This mechanism allows for the model to form a prediction based on two separate inputs, which allows us to track the progression of pleural effusion between two CXR images.</h3>
        <br>
        <h1>Output Discussion</h1>
        <table class="table">
            <tr class="tr">
                <th class="th">ImaGenome Dataset</th>
                <th class="th">Not Changed</th>
                <th class="th">Improved</th>
                <th class="th">Worsened</th>
            </tr>
            <tr class="tr">
                <th class="th">Not Changed</th>
                <td class="td"></td>
                <td class="td"></td>
                <td class="td"></td>
            </tr>
            <tr class="tr">
                <th class="th">Improved</th>
                <td class="td"></td>
                <td class="td"></td>
                <td class="td"></td>
            </tr>
            <tr class="tr">
                <th class="th">Worsened</th>
                <td class="td"></td>
                <td class="td"></td>
                <td class="td"></td>
            </tr>
        </table>
        <br>
        <h3>Here we may see that the Siamese neural networks' accuracy is slightly better than a random guess. In reality, this is due to the fact that it seems to always overgeneralize into always assuming that the CXR image is in the “no change” category. Overgeneralization is very common especially in tasks like this, which is why a multi-layer perceptron is used (fully-connected layers). In addition, a smaller learning rate helps with making the model slightly better at predicting the changes.</h3>
        <div class="images">
            <div class="image" style="width: 80%; flex: 0.7;">
                <img src="images/nochange.png">
            </div>
        </div>
        <div class="images">
            <div class="image" style="width: 80%; flex: 0.7;">
                <img src="images/yeschange.png">
                <div class="emergency_br"></div>
                <subtitle>
                    ImaGenome Samples
                </subtitle>
            </div>
        </div>
        <br>
        <h3>Another problem with CXR images and their description is its complexity with the many different organs that may influence the result, thus making it a much harder task. In addition to that, radiologists may sometimes disagree with their results, with one saying “nothing significant changed” while another saying otherwise. </h3>
        <h1>Last Words</h1>
        <h3>In conclusion, siamese neural networks offer a promising approach to detecting changes and tracking progress in medical imaging, especially in chest X-rays.
        This powerful technology can help medical professionals identify and intervene in conditions such as pleural effusion and other pathologies, perhaps even before they become symptomatic.
        The future of medical imaging with artificial intelligence is bright, and we are only scratching the surface of what is possible. 
        <br><br>Thank you very much for reading!</h3>
        <br>
        <h1>Resources and Links</h1>
        <ol>
            <li>GitHub Repository on Siamese Neural Networks</li>
            <li>ADL4CV:DV Lecture on Siamese Networks</li>
        </ol>
        <p style="color: white;">.</p>
    </div>
</body>

<script src="../script.js"></script>

</html>